<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Homework 8 - Comparing LLN and Random Walk</title>
    <meta name="description" content="Exploring the mathematical connections between the Law of Large Numbers and Random Walk simulations through combinatorial principles.">
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="../css/homework.css">
</head>
<body>
    <header class="header">
        <div class="header-content">
            <a href="../index.html" class="logo">
                Statistica Blog
            </a>
            <nav class="nav">
                <a href="../index.html" class="nav-link">Home</a>
                <a href="../index.html#homework" class="nav-link">Homework</a>
                <a href="#" class="nav-link">Info</a>
            </nav>
        </div>
    </header>

    <main class="main-content">
        <nav class="breadcrumb">
            <a href="../index.html">Home</a>
            <span class="breadcrumb-separator">›</span>
            <a href="../index.html#homework">Homework</a>
            <span class="breadcrumb-separator">›</span>
            <span class="breadcrumb-current">Week 5</span>
        </nav>

        <header class="article-header">
            <div class="article-meta">
                <span class="homework-week">Week 5</span>
                <span class="article-date">13 Nov 2025</span>
            </div>
            <h1 class="article-title">Comparing LLN and Random Walk: Mathematical Connections</h1>
            <div class="article-tags">
                <span class="tag">LLN</span>
                <span class="tag">Random Walk</span>
                <span class="tag">Binomial</span>
                <span class="tag">Combinatorics</span>
            </div>
        </header>

        <article class="article-content">
            
<section class="content-section">
    <h2>Homework Objectives</h2>
    <p>This theoretical assignment explores the deep connections between two fundamental probability simulations: the <b>Law of Large Numbers (LLN)</b> simulation from Homework 3 and the <b>Random Walk and Binomial Distribution</b> simulation from Homework 7. We analyze their similarities and differences, and illuminate the underlying mathematical structures involving <b>binomial coefficients</b>, <b>Pascal's triangle</b>, <b>binomial expansion</b>, the <b>Fibonacci sequence</b>, and <b>combinatorial principles</b>.</p>
</section>

<section class="content-section">
    <h2>Similarities Between the Two Models</h2>
    
    <div class="theory-block">
        <h3>1. Common Foundation: Bernoulli Processes</h3>
        <p>Both simulations are built upon <b>Bernoulli processes</b>, which consist of independent trials with binary outcomes.</p>
        <ul>
            <li><b>Binary Outcomes:</b> In LLN, each trial results in "success" or "failure". In Random Walk, each week results in "secure" (+1) or "breached" (-1).</li>
            <li><b>Independence:</b> Each trial is independent of previous trials in both models. The probability remains constant across all trials.</li>
            <li><b>Fixed Probability:</b> Both use a fixed probability <b>p</b> for one outcome and <b>(1-p)</b> for the other throughout the simulation.</li>
            <li><b>Multiple Trajectories:</b> Both generate <b>m</b> independent trajectories to observe the empirical behavior of the process.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>2. Convergence Phenomena</h3>
        <p>Both simulations demonstrate convergence as the number of trials or trajectories increases.</p>
        <ul>
            <li><b>LLN Convergence:</b> The relative frequency <b>f(n) = successes/n</b> converges to the theoretical probability <b>p</b> as n → ∞.</li>
            <li><b>Random Walk Convergence:</b> The empirical distribution of final scores converges to the theoretical binomial distribution as m → ∞.</li>
            <li><b>Law of Large Numbers:</b> Both demonstrate this fundamental principle: empirical frequencies approach theoretical probabilities with more trials.</li>
            <li><b>Visualization:</b> Both use histograms to show how empirical distributions align with theoretical expectations.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>3. Probabilistic Framework</h3>
        <p>Both models share the same underlying probability distribution: the binomial distribution.</p>
        <ul>
            <li><b>Counting Successes:</b> LLN tracks the cumulative count of successes k out of n trials.</li>
            <li><b>Score Transformation:</b> Random Walk score S = 2k - n, where k is the number of "secure" weeks. Thus, knowing S determines k uniquely.</li>
            <li><b>Binomial Formula:</b> The probability of k successes in n trials is <b>P(k) = C(n,k) × p^k × (1-p)^(n-k)</b> in both cases.</li>
            <li><b>Same Distribution:</b> The distribution of successes k in LLN is identical to the distribution of k = (S+n)/2 in Random Walk when using probability (1-p) for success.</li>
        </ul>
    </div>
</section>

<section class="content-section">
    <h2>Differences Between the Two Models</h2>
    
    <div class="theory-block">
        <h3>1. What They Measure</h3>
        <p>While built on the same foundation, the two simulations focus on different aspects of the Bernoulli process.</p>
        <ul>
            <li><b>LLN Focus:</b> Emphasizes the <b>convergence of relative frequency</b> to probability. Shows how f(n) oscillates around p and stabilizes as n increases.</li>
            <li><b>Random Walk Focus:</b> Emphasizes the <b>distribution of cumulative outcomes</b>. Shows how different trajectories spread out and create a distribution of final scores.</li>
            <li><b>Temporal vs. Distributional:</b> LLN is primarily temporal (watching convergence over time), while Random Walk is distributional (examining final outcomes across trajectories).</li>
            <li><b>Single vs. Multiple Endpoints:</b> LLN trajectories converge to one value (p), while Random Walk trajectories diverge to multiple possible scores.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>2. Visualization Approach</h3>
        <p>The two simulations present their data in complementary ways.</p>
        <ul>
            <li><b>LLN Trajectory:</b> Plots relative frequency f(n) ∈ [0,1] over time, showing convergence to p. All trajectories compress toward a single horizontal line.</li>
            <li><b>Random Walk Trajectory:</b> Plots cumulative score S ∈ [-n,n] over time, showing divergence. Trajectories fan out from the origin creating a spreading pattern.</li>
            <li><b>LLN Histogram:</b> Shows distribution of final frequencies f(n) across m trajectories. Should cluster tightly around p for large n.</li>
            <li><b>Random Walk Histogram:</b> Shows distribution of final scores S across m trajectories. Forms a binomial shape centered around expected value E[S] = n(1-2p).</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>3. Scale and Interpretation</h3>
        <p>The numerical scales and interpretations differ between the two models.</p>
        <ul>
            <li><b>LLN Range:</b> Relative frequency f(n) always lies in [0,1], representing a proportion or probability.</li>
            <li><b>Random Walk Range:</b> Score S lies in [-n,n], growing with n. Represents cumulative wins minus losses.</li>
            <li><b>LLN Interpretation:</b> "What proportion of trials were successful?" Answer converges to p.</li>
            <li><b>Random Walk Interpretation:</b> "What is the net cumulative outcome?" Answer follows a binomial distribution shifted and scaled: S = 2k - n.</li>
        </ul>
    </div>
</section>

<section class="content-section">
    <h2>Mathematical Connections</h2>
    
    <div class="theory-block">
        <h3>1. Binomial Coefficients and Pascal's Triangle</h3>
        <p>The <b>binomial coefficient</b> C(n,k) counts the number of ways to choose k successes from n trials, and is central to both simulations.</p>
        <ul>
            <li><b>Definition:</b> C(n,k) = n! / (k!(n-k)!), representing "n choose k".</li>
            <li><b>Pascal's Triangle:</b> Arranging C(n,k) values in triangular form creates Pascal's triangle, where each entry equals the sum of the two entries above it: C(n,k) = C(n-1,k-1) + C(n-1,k).</li>
            <li><b>Symmetry:</b> C(n,k) = C(n,n-k), reflecting the symmetry in choosing k items versus choosing n-k items to exclude.</li>
            <li><b>Probability Weight:</b> In both simulations, C(n,k) weights the probability of achieving exactly k successes, accounting for all possible orderings of successes and failures.</li>
        </ul>
        <div style="text-align: center; margin: 1.5rem 0; font-family: monospace;">
            <div>1</div>
            <div>1 1</div>
            <div>1 2 1</div>
            <div>1 3 3 1</div>
            <div>1 4 6 4 1</div>
            <div>1 5 10 10 5 1</div>
            <div style="margin-top: 0.5rem; font-size: 0.9em; color: #666;">Pascal's Triangle: Each row shows C(n,k) for k = 0 to n</div>
        </div>
    </div>

    <div class="theory-block">
        <h3>2. Binomial Expansion and Probability</h3>
        <p>The <b>binomial theorem</b> provides the algebraic foundation for the probability calculations in both models.</p>
        <ul>
            <li><b>Binomial Theorem:</b> (a + b)^n = Σ C(n,k) × a^k × b^(n-k), summing over k from 0 to n.</li>
            <li><b>Probability Application:</b> Setting a = p and b = (1-p), we get: 1 = (p + (1-p))^n = Σ C(n,k) × p^k × (1-p)^(n-k). This shows all probabilities sum to 1.</li>
            <li><b>Each Term:</b> The term C(n,k) × p^k × (1-p)^(n-k) is the probability of exactly k successes in n trials, used in both simulations.</li>
            <li><b>Generating Function:</b> The binomial expansion acts as a generating function for the probability distribution, encoding all possible outcomes.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>3. Connection to Fibonacci Sequence</h3>
        <p>The <b>Fibonacci sequence</b> appears naturally when examining paths in Pascal's triangle and certain random walk properties.</p>
        <ul>
            <li><b>Fibonacci Definition:</b> F(0) = 0, F(1) = 1, F(n) = F(n-1) + F(n-2) for n ≥ 2, giving sequence: 0, 1, 1, 2, 3, 5, 8, 13, 21, ...</li>
            <li><b>Pascal's Diagonal Sums:</b> Summing along shallow diagonals of Pascal's triangle yields Fibonacci numbers. For example: 1 = F(2), 1+1 = F(3), 1+2 = F(4), 1+3+1 = F(5), 1+4+3 = F(6).</li>
            <li><b>Combinatorial Interpretation:</b> F(n) counts the number of ways to tile a 1×(n-1) board with 1×1 and 1×2 tiles, related to counting certain types of paths.</li>
            <li><b>Random Walk Connection:</b> In symmetric random walks (p=0.5), the number of paths returning to origin after 2n steps relates to central binomial coefficients C(2n,n), which grow similarly to Fibonacci numbers in recursive structure.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>4. Combinatorial Coefficients and Counting</h3>
        <p>Understanding <b>combinatorics</b> is essential for interpreting both simulations and their convergence properties.</p>
        <ul>
            <li><b>Path Counting:</b> C(n,k) counts the number of distinct paths from start to k successes in n trials. Each path represents a unique sequence of outcomes.</li>
            <li><b>Multiplicity:</b> When simulating, outcomes with higher C(n,k) appear more frequently because there are more ways to achieve them. This creates the characteristic bell shape of the binomial distribution.</li>
            <li><b>Lattice Paths:</b> In Random Walk, each trajectory can be viewed as a path on a 2D lattice. The number of paths reaching score S after n steps is C(n, (S+n)/2).</li>
            <li><b>Ballot Problem:</b> Related counting problems, like the ballot theorem, use similar combinatorial reasoning to count constrained paths, extending these concepts to more complex scenarios.</li>
        </ul>
    </div>

    <div class="theory-block">
        <h3>5. Expected Values and Variance</h3>
        <p>Both models share the same underlying expected value and variance formulas derived from the binomial distribution.</p>
        <ul>
            <li><b>Expected Successes:</b> E[k] = np for both models. In LLN, E[f(n)] = E[k/n] = p. In Random Walk, E[S] = E[2k-n] = 2np - n = n(2p-1).</li>
            <li><b>Variance:</b> Var(k) = np(1-p) for both. In LLN, Var(f(n)) = Var(k/n) = p(1-p)/n → 0 as n → ∞. In Random Walk, Var(S) = Var(2k) = 4np(1-p).</li>
            <li><b>Standard Deviation:</b> σ(k) = √(np(1-p)). For LLN convergence, σ(f(n)) = √(p(1-p)/n) decreases with n. For Random Walk spread, σ(S) = 2√(np(1-p)) increases with n.</li>
            <li><b>Central Limit Theorem:</b> For large n, both distributions approach normal distributions: f(n) → N(p, p(1-p)/n) and S → N(n(2p-1), 4np(1-p)).</li>
        </ul>
    </div>
</section>

<section class="content-section">
    <h2>Unified Mathematical Framework</h2>
    
    <div class="theory-block">
        <h3>Deep Connection: Two Views of One Process</h3>
        <p>Ultimately, the LLN simulation and Random Walk simulation are two different perspectives on the same underlying Bernoulli process.</p>
        <ul>
            <li><b>LLN Perspective:</b> Normalize by n to study relative frequency f(n) = k/n. Focus on convergence to a fixed probability p. Variance decreases as O(1/n).</li>
            <li><b>Random Walk Perspective:</b> Transform to score S = 2k - n. Focus on distributional shape across trajectories. Variance increases as O(n).</li>
            <li><b>Same Information:</b> Given n and either f(n) or S, we can compute k uniquely. The transformations are bijective: k = nf(n) = (S+n)/2.</li>
            <li><b>Complementary Insights:</b> LLN shows why empirical measurements become reliable (convergence), while Random Walk shows how outcomes distribute when cumulative effects matter (spreading). Both are essential for understanding stochastic processes.</li>
        </ul>
    </div>
</section>

<section class="content-section">
    <h2>Summary Table</h2>
    <div class="table-scroll-container">
    <table>
        <thead>
            <tr>
                <th>Aspect</th>
                <th>LLN Simulation (HW3)</th>
                <th>Random Walk Simulation (HW7)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><b>Primary Focus</b></td>
                <td>Convergence of relative frequency</td>
                <td>Distribution of cumulative scores</td>
            </tr>
            <tr>
                <td><b>Measured Quantity</b></td>
                <td>f(n) = k/n ∈ [0,1]</td>
                <td>S = 2k - n ∈ [-n,n]</td>
            </tr>
            <tr>
                <td><b>Trajectory Behavior</b></td>
                <td>Converges to p (compression)</td>
                <td>Spreads from 0 (divergence)</td>
            </tr>
            <tr>
                <td><b>Expected Value</b></td>
                <td>E[f(n)] = p (constant)</td>
                <td>E[S] = n(2p-1) (linear in n)</td>
            </tr>
            <tr>
                <td><b>Variance</b></td>
                <td>Var(f(n)) = p(1-p)/n → 0</td>
                <td>Var(S) = 4np(1-p) → ∞</td>
            </tr>
            <tr>
                <td><b>Histogram Shape</b></td>
                <td>Narrow peak near p (for large n)</td>
                <td>Binomial bell curve (for large m)</td>
            </tr>
            <tr>
                <td><b>Demonstrates</b></td>
                <td>Law of Large Numbers</td>
                <td>Binomial Distribution</td>
            </tr>
            <tr>
                <td><b>Common Foundation</b></td>
                <td colspan="2" style="text-align: center;">Bernoulli Process: k successes in n independent trials</td>
            </tr>
        </tbody>
    </table>
    </div>
</section>

<section class="content-section">
    <h2>Conclusion</h2>
    <p>
        The Law of Large Numbers simulation and the Random Walk simulation, while visually and conceptually distinct, are mathematically equivalent representations of the binomial distribution arising from Bernoulli processes. The LLN emphasizes temporal convergence of proportions to theoretical probabilities, demonstrating why statistical inference works. The Random Walk emphasizes distributional properties of cumulative outcomes, showing how probabilistic systems evolve and spread. Together, they provide complementary insights into one of probability theory's most fundamental structures, unified by the elegant mathematics of binomial coefficients, Pascal's triangle, and combinatorial counting.
    </p>
</section>

        </article>
    </main>
</body>
</html>